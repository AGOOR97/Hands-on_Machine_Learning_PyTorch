{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook provides some Notes about CNN using PyTorch for custom DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check data on Kaggle : https://www.kaggle.com/c/arabic-hwr-ai-pro-intake1/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:15.179828Z",
     "iopub.status.busy": "2021-12-11T19:29:15.179472Z",
     "iopub.status.idle": "2021-12-11T19:29:16.221041Z",
     "shell.execute_reply": "2021-12-11T19:29:16.220123Z",
     "shell.execute_reply.started": "2021-12-11T19:29:15.179780Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:16.223035Z",
     "iopub.status.busy": "2021-12-11T19:29:16.222565Z",
     "iopub.status.idle": "2021-12-11T19:29:16.227847Z",
     "shell.execute_reply": "2021-12-11T19:29:16.226844Z",
     "shell.execute_reply.started": "2021-12-11T19:29:16.222984Z"
    }
   },
   "outputs": [],
   "source": [
    "## device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and prepare The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:16.231482Z",
     "iopub.status.busy": "2021-12-11T19:29:16.231154Z",
     "iopub.status.idle": "2021-12-11T19:29:16.239798Z",
     "shell.execute_reply": "2021-12-11T19:29:16.239043Z",
     "shell.execute_reply.started": "2021-12-11T19:29:16.231437Z"
    }
   },
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "learning_rate = 0.001\n",
    "n_epochs = 100\n",
    "n_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:16.241957Z",
     "iopub.status.busy": "2021-12-11T19:29:16.241349Z",
     "iopub.status.idle": "2021-12-11T19:29:16.489402Z",
     "shell.execute_reply": "2021-12-11T19:29:16.488435Z",
     "shell.execute_reply.started": "2021-12-11T19:29:16.241911Z"
    }
   },
   "outputs": [],
   "source": [
    "## Note that these paths is on kaggle --> check the above link for data\n",
    "\n",
    "train_labels = pd.read_csv('../input/arabic-hwr-ai-pro-intake1/train.csv')\n",
    "train_images = Path(r'../input/arabic-hwr-ai-pro-intake1/train')\n",
    "\n",
    "## read these all training images paths as Series\n",
    "train_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)\n",
    "\n",
    "train_images_paths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:16.491845Z",
     "iopub.status.busy": "2021-12-11T19:29:16.491180Z",
     "iopub.status.idle": "2021-12-11T19:29:17.844345Z",
     "shell.execute_reply": "2021-12-11T19:29:17.843678Z",
     "shell.execute_reply.started": "2021-12-11T19:29:16.491805Z"
    }
   },
   "outputs": [],
   "source": [
    "img_key_value = {}\n",
    "for value in train_labels['label'].unique():\n",
    "    img_key_value[value] = train_labels[train_labels['label']==value].index[0]\n",
    "    \n",
    "img_index = list(img_key_value.values())\n",
    "img_label = list(img_key_value.keys())\n",
    "\n",
    "fig, ax = plt.subplots(4, 7, figsize=(12, 8))\n",
    "\n",
    "i = 0\n",
    "for row in range(4):\n",
    "    for col in range(7):\n",
    "        plt.sca(ax[row, col])\n",
    "        plt.title(f'label = {img_label[i]}')\n",
    "        img = plt.imread(train_images_paths.iloc[img_index[i]])\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:17.846413Z",
     "iopub.status.busy": "2021-12-11T19:29:17.845450Z",
     "iopub.status.idle": "2021-12-11T19:29:28.150389Z",
     "shell.execute_reply": "2021-12-11T19:29:28.149428Z",
     "shell.execute_reply.started": "2021-12-11T19:29:17.846360Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of Instances in train_set =>', len(train_images_paths))\n",
    "print('Number of Instances in train_labels =>', len(train_labels))\n",
    "img = plt.imread(train_images_paths.iloc[img_index[0]])\n",
    "print('shape of each Image is =>', img.shape)\n",
    "print()\n",
    "\n",
    "train_full_labels = train_labels['label'].values\n",
    "train_full_set = np.empty((13440, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n",
    "\n",
    "for idx, path in enumerate(train_images_paths):\n",
    "    img = plt.imread(path)\n",
    "    img = img[:,:,:3]\n",
    "    train_full_set[idx] = img\n",
    "print()\n",
    "print('train_full_set.shape =>', train_full_set.shape)\n",
    "print('train_full_labels.shape =>', train_full_labels.shape)\n",
    "print()\n",
    "\n",
    "## for labels\n",
    "train_full_labels = (train_labels['label'] - 1).values  ## to start from 0\n",
    "print('train_full_labels.shape =>', train_full_labels.shape)\n",
    "\n",
    "\n",
    "## split the Dataset\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_full_set, train_full_labels, \n",
    "                                                      test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "### to float32 then to tensors\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_valid = torch.from_numpy(X_valid.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_valid = torch.from_numpy(y_valid.astype(np.float32))\n",
    "## reshape\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_valid = y_valid.reshape(-1, 1)\n",
    "\n",
    "## PyTorch want to get the Channels first\n",
    "X_train = torch.permute(X_train, (0, 3, 1, 2))\n",
    "X_valid = torch.permute(X_valid, (0, 3, 1, 2))\n",
    "##  for target  --> this is a MUST\n",
    "y_train = y_train.type(torch.LongTensor)\n",
    "y_valid = y_valid.type(torch.LongTensor)\n",
    "\n",
    "print()\n",
    "print('X_train.shape =>', X_train.shape)\n",
    "print('X_valid.shape =>', X_valid.shape)\n",
    "print('y_train.shape =>', y_train.shape)\n",
    "print('y_valid.shape =>', y_valid.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:28.152099Z",
     "iopub.status.busy": "2021-12-11T19:29:28.151776Z",
     "iopub.status.idle": "2021-12-11T19:29:28.162438Z",
     "shell.execute_reply": "2021-12-11T19:29:28.160696Z",
     "shell.execute_reply.started": "2021-12-11T19:29:28.152067Z"
    }
   },
   "outputs": [],
   "source": [
    "## create two classes one for train and other for validation\n",
    "\n",
    "class TrainingDataSet(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        # get X (features) and y(taregt) ---> to tensors\n",
    "        self.features = X_train\n",
    "        self.target = y_train\n",
    "        \n",
    "        self.n_samples = X_train.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ## data indexing \n",
    "        return self.features[index], torch.squeeze(self.target[index])\n",
    "        \n",
    "    def __len__(self):\n",
    "        ## data length\n",
    "        return self.n_samples\n",
    "    \n",
    "############################ --------------------------------------- ############################\n",
    "\n",
    "class ValidationDataSet(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        # get X (features) and y(taregt) ---> to tensors\n",
    "        self.features = X_valid\n",
    "        self.target = y_valid\n",
    "        \n",
    "        self.n_samples = X_valid.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ## data indexing \n",
    "        return self.features[index], torch.squeeze(self.target[index])\n",
    "        \n",
    "    def __len__(self):\n",
    "        ## data length\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:28.164130Z",
     "iopub.status.busy": "2021-12-11T19:29:28.163872Z",
     "iopub.status.idle": "2021-12-11T19:29:28.179057Z",
     "shell.execute_reply": "2021-12-11T19:29:28.178146Z",
     "shell.execute_reply.started": "2021-12-11T19:29:28.164097Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = TrainingDataSet()\n",
    "valid_dataset = ValidationDataSet()\n",
    "\n",
    "## create the dataloader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=n_batch_size, \n",
    "                          shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=n_batch_size, \n",
    "                          shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:28.194883Z",
     "iopub.status.busy": "2021-12-11T19:29:28.194639Z",
     "iopub.status.idle": "2021-12-11T19:29:28.206854Z",
     "shell.execute_reply": "2021-12-11T19:29:28.206064Z",
     "shell.execute_reply.started": "2021-12-11T19:29:28.194853Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_size = {'512':512, '256':256, '128':128, '64':64, '32':32}\n",
    "num_classes = len(np.unique(y_train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:28.208760Z",
     "iopub.status.busy": "2021-12-11T19:29:28.208380Z",
     "iopub.status.idle": "2021-12-11T19:29:28.221589Z",
     "shell.execute_reply": "2021-12-11T19:29:28.220593Z",
     "shell.execute_reply.started": "2021-12-11T19:29:28.208724Z"
    }
   },
   "outputs": [],
   "source": [
    "## \n",
    "class ConvNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNeuralNetwork, self).__init__()\n",
    "        \n",
    "        ## conv_base  ---> images input 32*32*1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding='same')\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding='same')\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        ## top_clf\n",
    "        ## made flatten by yourself ---> 64 is the previuos channels --> 6x6 is window at this step\n",
    "        self.fc1 = nn.Linear(in_features=64*8*8, out_features=256)   ## 256 neurons\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=256)       ## 256 neurons\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=28)   ## 28 classes\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = f.relu(self.conv1(x))\n",
    "        out = self.pool1(out)\n",
    "        out = f.relu(self.conv2(out))\n",
    "        out = f.relu(self.conv3(out))\n",
    "        out = self.pool2(out)\n",
    "        \n",
    "        ## Flatten\n",
    "        out = out.view(-1, 64*8*8)  \n",
    "        out = f.relu(self.fc1(out))\n",
    "        out = f.relu(self.fc2(out))\n",
    "        out = self.fc3(out)   ## for softmax --> No Activation function at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T19:29:28.225897Z",
     "iopub.status.busy": "2021-12-11T19:29:28.225366Z",
     "iopub.status.idle": "2021-12-11T20:00:06.906827Z",
     "shell.execute_reply": "2021-12-11T20:00:06.905875Z",
     "shell.execute_reply.started": "2021-12-11T19:29:28.225843Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Define the Model\n",
    "model = ConvNeuralNetwork().to(device=device)\n",
    "\n",
    "## Criteria\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "## Training\n",
    "print('Training Started _____________________________________ \\n')\n",
    "\n",
    "n_iterations = len(train_loader)    ## --> = len(train_dataset)/n_batch_size\n",
    "n_train_samples = 0\n",
    "n_train_correct = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'## epoch No. {epoch+1}')\n",
    "    for i, (train_images, train_labels) in enumerate(train_loader):\n",
    "        \n",
    "        ## images shape ---> batch_size * channels * height * width (32, 3, 32, 32)\n",
    "        train_images = train_images.to(device=device)\n",
    "        train_labels = train_labels.to(device=device)\n",
    "        \n",
    "        ## forward pass\n",
    "        y_train_pred = model(train_images)\n",
    "        ## loss\n",
    "        l = loss(y_train_pred, train_labels)\n",
    "        \n",
    "        ## we can empty gradients first\n",
    "        optimizer.zero_grad()\n",
    "        ## backward\n",
    "        l.backward()\n",
    "        ## step\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## during training\n",
    "        ## return value and index --> i care about index of max score\n",
    "        _, y_train_pred_cls = torch.max(y_train_pred, dim=1)\n",
    "        \n",
    "        ## modify\n",
    "        n_train_samples += train_labels.shape[0]\n",
    "        n_train_correct += (y_train_pred_cls==train_labels).sum().item()\n",
    "        train_accuracy = (n_train_correct/n_train_samples) * 100.0\n",
    "        \n",
    "        print(f'## Iteration No. {i+1}, loss={l:.5f}, acc={train_accuracy:.3f}')\n",
    "        \n",
    "print('Training is finished ___________________________')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T20:00:06.908872Z",
     "iopub.status.busy": "2021-12-11T20:00:06.908551Z",
     "iopub.status.idle": "2021-12-11T20:00:08.232144Z",
     "shell.execute_reply": "2021-12-11T20:00:08.231414Z",
     "shell.execute_reply.started": "2021-12-11T20:00:06.908837Z"
    }
   },
   "outputs": [],
   "source": [
    "## to prevent (requires_grad=True) during evaluation\n",
    "with torch.no_grad():    \n",
    "    n_valid_correct = 0\n",
    "    n_valid_samples = 0\n",
    "    \n",
    "    for i, (images_valid, valid_labels) in enumerate(valid_loader):\n",
    "         ## images shape ---> batch_size * channels * height * width (32, 3, 32, 32)\n",
    "        images_valid = images_valid.to(device=device)\n",
    "        valid_labels = valid_labels.to(device=device)\n",
    "        \n",
    "        y_valid_pred = model(images_valid)\n",
    "        \n",
    "        ## return value and index --> i care about index of max score\n",
    "        _, y_valid_pred_cls = torch.max(y_valid_pred, dim=1)\n",
    "        \n",
    "        ## modify\n",
    "        n_valid_samples += valid_labels.shape[0]\n",
    "        n_valid_correct += (y_valid_pred_cls==valid_labels).sum().item()\n",
    "                \n",
    "valid_accuracy = (n_valid_correct/n_valid_samples) * 100.0\n",
    "print(f'Validation accuracy is --> {valid_accuracy:.4f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T20:09:30.457796Z",
     "iopub.status.busy": "2021-12-11T20:09:30.456890Z",
     "iopub.status.idle": "2021-12-11T20:09:30.464094Z",
     "shell.execute_reply": "2021-12-11T20:09:30.463104Z",
     "shell.execute_reply.started": "2021-12-11T20:09:30.457728Z"
    }
   },
   "outputs": [],
   "source": [
    "## total accuracy\n",
    "n_correct = n_train_correct + n_valid_correct\n",
    "n_samples = n_train_samples + n_valid_samples\n",
    "\n",
    "total_acc = (n_correct / n_samples) * 100\n",
    "print(f'Total Accuracy for full Training Data --> {total_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
