{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5933c1",
   "metadata": {},
   "source": [
    "### This Notebook Provides some Notes about using PyTorch for LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bcf9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84bcc14",
   "metadata": {},
   "source": [
    "### `Building a Simple Linear Regression Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b077ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading and preparing the dataset\n",
    "## using only 5 features and 1000 sample(800 for train and 200 for test)\n",
    "data_reg = datasets.make_regression(n_samples=1000, n_features=5, noise=20, random_state=42)\n",
    "\n",
    "X = data_reg[0]\n",
    "y = data_reg[1]\n",
    "\n",
    "# reshape y\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "## split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    shuffle=True, random_state=42)\n",
    "\n",
    "## standardize the dataset\n",
    "sacler = StandardScaler()\n",
    "X_train_scaled = sacler.fit_transform(X_train)\n",
    "X_test_scaled = sacler.transform(X_test)\n",
    "\n",
    "## convert to float32 then convert to tensors\n",
    "X_train_scaled = torch.from_numpy(X_train_scaled.astype(np.float32))\n",
    "X_test_scaled = torch.from_numpy(X_test_scaled.astype(np.float32))\n",
    "\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58570a91",
   "metadata": {},
   "source": [
    "#### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdb9bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started ____________________________________ \n",
      "\n",
      "Training finished ____________________________________ \n",
      "\n",
      "\n",
      "MSE train --> 3220.382568359375\n",
      "weight --> [[4.5369606 8.554383  3.3953743 4.686488  3.1131282]]\n",
      "bias --> [0.27149644]\n"
     ]
    }
   ],
   "source": [
    "## build the Model\n",
    "input_size = X_train_scaled.shape[1]\n",
    "output_size = 1   ## taregt\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin_reg = nn.Linear(in_features=input_dim, out_features=output_dim)\n",
    "        \n",
    "    def forward(self, x):   ## predicting functions\n",
    "        out = self.lin_reg(x)\n",
    "        return out\n",
    "    \n",
    "lin_reg = LinearRegression(input_size, output_size)  ## create an instance\n",
    "\n",
    "\n",
    "## Training\n",
    "print('Training started ____________________________________ \\n')\n",
    "\n",
    "## criteria\n",
    "learning_rate = 0.001\n",
    "n_epochs = 100\n",
    "\n",
    "loss = nn.MSELoss()   ## usin MSE\n",
    "optimizer = torch.optim.SGD(lin_reg.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    ## predicting\n",
    "    y_pred_train = lin_reg(X_train_scaled)\n",
    "    ## cal the loss\n",
    "    l = loss(y_train, y_pred_train)\n",
    "    ## backpropagation\n",
    "    l.backward()\n",
    "    ## taka an optimization step\n",
    "    optimizer.step()\n",
    "    ## empty the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print('Training finished ____________________________________ \\n') \n",
    "print()\n",
    "mse_train = loss(y_pred_train, y_train)    \n",
    "print('MSE train -->', mse_train.item())\n",
    "\n",
    "[w, b] = lin_reg.parameters()\n",
    "print('weight -->', w.detach().numpy())\n",
    "print('bias -->', b.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d94651",
   "metadata": {},
   "source": [
    "#### `Evaluation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d9baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train --> 2976.050048828125\n"
     ]
    }
   ],
   "source": [
    "## you must stop gradient during inference to not kick the gradient graph during inference\n",
    "with torch.no_grad():\n",
    "    y_pred_test = lin_reg(X_test_scaled)\n",
    "    mse_test = loss(y_test, y_pred_test)\n",
    "    print('MSE train -->', mse_test.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab6aa9",
   "metadata": {},
   "source": [
    "#### Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
